{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise consists of 3 parts. Finish the first part to get the mark of 3.0. The first 2 parts to get 4.0. Finish all parts to get 5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) Let us start with a linear regression problem. Consider a linear function with a noise: $y = a*x+b + noise$.\n",
    "\n",
    "We use this formula to generate $100$ random smaples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The number of samples\n",
    "n = 100 \n",
    "### parameters of the linear function\n",
    "a = -2 \n",
    "b = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Now, let us generate 100 samples and plot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d16e7d0ca0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaKUlEQVR4nO3df4xlZX3H8c+XYYBLrcwiU8sOwi6phVKJu2ZCSbepsm2BqoGttQUTW2xttlrTVKy0Q02qaWLYlqSYpiaWqNXWFtcibGnRUnQgpBuhne2uIuIKokZGKqswVrvT7bD77R/33OXM3fPznh/3ufe+X8lm7px777kPZ4bveeb7fJ/nMXcXACBcJw27AQCAbARqAAgcgRoAAkegBoDAEagBIHAnN3HSs846yzdt2tTEqQFgLO3bt+877j6b9FwjgXrTpk1aWlpq4tQAMJbM7Btpz5H6AIDAEagBIHAEagAIHIEaAAJHoAaAwDVS9VHVnv3Luvmeg/rWyqo2znR0wxUXaMfWuWE3CwCGIrhAvWf/sm6842Gtrh2VJC2vrOrGOx6WJII1gIkUXOrj5nsOHg/SPatrR3XzPQeH1CIAGK7gAvW3VlZLHQeAcRdcoN440yl1HADGXXCB+oYrLlBnemrdsc70lG644oIhtQgAhiu4wcTegCFVHwDQFVyglrrBmsAMAF3BpT4AAOsRqAEgcARqAAgcgRoAAkegBoDABVn10TYWgQIQsokP1CwCBSB0E5/6YBEoAKELpkc9rPQDi0ABCF0QPepe+mF5ZVWu59MPe/YvN/7ZLAIFIHRBBOphph9YBApA6AqlPszs65K+L+mopOfcfb7ORlRNP1RJm7AIFIDQlclRX+bu32miERtnOlpOCMpF0g9FqzaygjmLQAEIWRCpjyrphyJpk2HmwAGgqqKB2iX9q5ntM7OdSS8ws51mtmRmS4cOHSrViB1b53TT6y7W3ExHJmlupqObXndxoV5ukbQJJXgARlnR1MfPuPuymf2IpHvN7Mvu/kD8Be5+q6RbJWl+ft7LNmTQ9EORtAkleABGWaEetbsvR1+flnSnpEuabFQZRdImlOABGGW5gdrMfsjMfrj3WNLlkr7YdMOKKpI2SQrmpm6uetuuRXLVAIJWJPXxYkl3mlnv9X/v7v/SaKtKSkubxCs9zuhM67Tpk/Ts4TWZukl3ibU9AIQvN1C7+xOSXt5CW2rVX7a3srqmzvSUNpw+rWcPr617bW9gkUANIETBrPVRt7RKj/5jPQwsAgjVSAXqMjMQywbe3sAia1MDCE3wgboXOJdXVkvlltPK9mY60zry3LF1PetelQhrUwMIURAzE9PEZxRKzwfpntW1o3r77gOJlRtpZXvvueonU6tEmBgDIERB96iTAmeSpJ5v3mJLST3krIkxpEQADEvQgbpMnjmpcqPsbMe0dMkZnenGUyLcCACkCTr1UXbmYNXKjbR0iZkaTYmwaBSALEEH6rQZhWmqTglPm+W40ld33VNXSR+5cQBZgk59pOWZJa1LRUjrKzeqpBCS0iW9qpN+da0VwqJRALIEHail7DxzXgCvK5d8wxUXpN4Y6lBl4wQA4y/4QJ0mKYBv27WYmkKoEqiLbtc1aG++6RsBgNE2soE6SZMphLwKkiqTZdi3EUCWsQrUw0whZA0IFgm4RUsJKeMDJk/QVR9lVdl7sao2BgQp4wMm01gF6ip7L1bVxi4ylPEBk2msUh/S4HsvVtXGgCBT3IHJNHaBeljaGBAc5hR3AMNj7qU3DM81Pz/vS0tLtZ+3baH1UvsrS6Rur723xVi/uZmO9i5sb7OJAAZkZvvcfT7pubHKUdcpxIG7YU1xBzBcpD5SVC23a8owprgDGC561CmGuf7Gnv3L2rZrUZsX7k7cFKHfMMsSATSPHnWKopNn6s5jDzLDkZmNwHhjMDFF2sBdvC476zVScuDMC+zbdi0m3iDKDAyGNggKIF/WYCI96hRFeqlpeez33PXIug10e73ipW88o0/uW87sLVdNubBBLzB+CNQZ8ibPpAXPldUTqzBW147qtoe+qaN9f8H0D1BWXa8k1EFQAIMjUFeQFlTT9AfpnnjALzPDMSnFwSYEwPih6qOCtGqLDadPlzqPS8erO4quV5JW5z2T8tmU6gGjix51BWW2CsvTn0uOB+ZeuV78M9JSHKeefJI601NsQgCMEao+GtJLS5RJjUgnVnekVZak3QRM0i3XbKHqAxgxVH0MQa9XvHnhbpW5FfbnktN6zlNmiTnvjTOdoa0gCKAZ5KgblpYbnjIr9Pq0QcCj7sxGBCYEgXoAZaZ4pw04vuGnXlIo0KYF+t4g4zA2SQDQrsKpDzObkrQkadndX9tck8JWdkJJ1sSZ+fPOzM0lZ5XrNZHiYFYjEJ7Cg4lm9g5J85JemBeox3kwsY4p3mW1FTyLTJsH0IzKg4lmdo6k10h6r6R31Ni2kTOMCSVtDQ4yqxEIU9Ec9fsk/YGkY2kvMLOdZrZkZkuHDh2qo21BamMT22FhViMQptxAbWavlfS0u+/Lep273+ru8+4+Pzs7W1sDQzPOaz+P800IGGVFUh/bJF1lZq+WdJqkF5rZx9z9jc02LUyjvPZzPNd9RmdaZtLK4bXj/w1t7KQOoLxSMxPN7FWS3jnJg4mjKmmgMC5vHW0AzWJmIhIHCuN6g4Z7F7YTmIHAlArU7n6/pPsbaQkaVWRAkEFDIEzMTJwQRQYEGTQEwkSgnhBJ1SpxDBoC4SJHPSH6q1WSqj7ITQNhIlCPuWGu3cG6IUA9CNRjbJg7khf9bII5kI8c9RjLWrsjhM9O2/cxa9lYYBIRqMfYMNfuKPLZw7yRAKOEQD3Ghrl2R5HPZhEooBgC9Rgb5gJSRT6bRaCAYhhMHGNVF5DKW8Qp6zxFPrvORaAYlMQ4K7UoU1EsyjT6ii7iVDUYpt0MytwY2JkG4yBrUSZSH0hUdBGnqnZsndPehe265ZotOvLcMT17eE0uaWV17fjjvGoQBiUx7gjUSNT2Ik5VbgwMSmLckaNGoo0zncRNfPtf02/QXHGVG0NaWxmUxLigR41EgyziVGUCS5XV/cZ5ezRAIlAjxY6tc7rpdRdrbqYjkzTTmdaG06ePPz5t+iRdv/uAtu1aPB6Is3LFe/Yva9uuRW1euHvde3qqrO7X39a5mQ4DiRgrVH2glKwKi+t3H1Dab1Nneiq3KqNKOSAw6rKqPgjUKGXbrsXEfPBclJZIem7KTEcTfs/mZjrau7C9/kYCI4jyPNQmbUBveWVV/3PkOU1P2brjnempxCCddS4A6xGoUUrWoN/K6prkOp7L7uWK55gqDlRCeR5KSZr2Hbd2zHX6KSdr/x9fvu54XVPFgUlEoEYp8TU80uqs+1MaVdccASYdgRqlJ6ns2DqnHVvnUgcWk1IavfeMMhZ+wrCQo55wVSapDDrRJK+mOkTsRoNhIlBPuCoLGg0y0WRUAx4LP2GYSH1MuKoLGpVNaWQFvJDTCCz8hGGiRz3h2t5lZVQDHrvRYJgI1BOu7QWNBgl4IeS0WfgJw0SgnnBtL2hUNuCFktNm4ScME2t9oHVlytyy1hZJWyeEMjqMoqy1PhhMROvKDEBmrS2ybdfiCUG4f3W/Xg+897nAKCL1gaBl5a6T0iCU0WEcEagRtLwNBfqD8KhWlQBZclMfZnaapAcknRq9/nZ3f3fTDQOk8muL5O2fSP4ao6hIj/qIpO3u/nJJWyRdaWaXNtoqIGbH1jntXdheaLnUrKqSUCpIgLJyA7V3/SD6djr6V3+pCJAjKQibnh9Y3LN/ObOMjvw1RlWhqg8zm5K0T9KPSXq/uz+U8JqdknZK0rnnnltnGwFJJ6ZBTM/3GPqrO5LSGYPkr0mVIASFBhPd/ai7b5F0jqRLzOxlCa+51d3n3X1+dna25mYCXfE0SP+fdUm94/isxpPMlCStsoRUCUJRqurD3Vck3SfpykZaAxRUpHfcH2iT9m7MmhU5SKokhOnuGD+5gdrMZs1sJnrckfQLkr7ccLuATEXWDEkKtFJ3V/Qi08DLpkrogaMpRXLUZ0v6aJSnPknSJ9z9n5ttFpAtae/G/t5xWkA95q6v7XrNumNJuei8Ur9+o7qEK8KXG6jd/QuStrbQFqCwIvswFg20SdPOr999QC6tG7CUklMlvSBfdA9JoCzW+sDIylszpEivW0ruCXvsay9YzyXcDPqDfBLWrEZVBGqMraK7n+f1eHtBOmm1vrQ8eE+ba1ZTSji+CNQYa0VW6ktLkcQNUoOd1ANvCqsGjjcWZcLEy1v4SSq/M02vB95WkGTW5XgjUGPixaedS92cdFxW+iKULbpYNXC8kfoAtD5FUibXWzQPPogy7ShbSojRwlZcQICSqkk601OpE3TKvh7hydqKi9QHEKCyOWc23x1vpD6AATRdCjdIzrnMXpQYLQRqTKxBg23RUrj4+c/oTMtMWjm8VuizyDkjjtQHJlKVBZSKpCX6z7+yuqZnD68V/qxQqkkQBgI1JlKVuuMiaYm8GYt5n0XOGXGkPjCRqtQdF0lLFDlP3mvIOaOHHjUmUtmZhnFF0hJFzrNxpsNGAyiEQI2JVCUHXCQtkTctvTM9pcsunB3qRgPcJEYHE14wsZousUur+ug9fvbwWuL70lbqqxMTZMKTNeGFQA20qMj61SadsANN3bbtWkzMs7dxk0AyZiYCgcirBpHaqZVmEafRQtUH0KK8QFi2VnrQ9A0TakYLPWqgRVmBsGytdJVJO0yoGS30qIEWpe3jWDZAp22mW3TX8yaXZ0X9CNRAi6oGyCKDkUXzzEyoGR0EaqBlVQJkKIORaBeBGghEkYHBugcjMRoI1EAAii6dmrVjel27ntc5EajpSUWTgqoPIABFV/NLq9Z43zVbatn1vEolSZPnmnQEaiAARSegNL38aZnlX/PWCqmylCzWI/UBBKDMBJQmqzWK3jCKpGqY/VgfetRAAEKZgFJ0+dciveUqS8liPQI1EIBQdnRJumGYuj3meHqjSG85lJvPOCD1AQQihAko8Qk5yyurMkm99TXj6Y0iqRpmP9aHZU4BJMpaCjVpKnwvqNdVJjhpspY5pUcNjIC66pHLnCcrvVG0502wrkdujtrMXmJm95nZl8zsETP7vTYaBqCrrnrksufJGwzcsXVOexe2a26mo/6/yynDq1eRwcTnJP2+u18k6VJJbzOzi5ptFoCeuuqRy56n6GAgZXjNyw3U7v6Uu/9n9Pj7kh6VxN8zQEvqCoRlz1O0EoUyvOaVylGb2SZJWyU9lPDcTkk7Jencc8+to20ANNhuLEm56EHOU6QSJW2Nbcrw6lO4jtrMXiDpk5Le7u7/3f+8u9/q7vPuPj87O1tnG4GJVrYeOSkXff3uA8cH/Yqep6hQasDHWaEetZlNqxuk/87d72i2SQDiytYjJ+WiPfa1iTK6EGrAx1luoDYzk/QhSY+6+5833yQA/coEwrzcdS9I713YXkPL0IYiPeptkn5N0sNmdiA69kfu/qnGWgVgYFlrVveEVJHBmtX5cgO1u/+bdEJqC0Cgkgb3+oVSkVF0w4RJx6JMwJiJD+5JJ/ayQqrIYM3qYphCDoyheE475NQCk2WKIVADYy7kioxBarsnEakPAEPDmtXF0KMGUEgTKRTWrC6GQA0gV5PVGSGnZkJBoAaQK6s6o+0gG/LgaFMI1AByhVKdMal11wwmAsgVylKmk1p3TaAGkGvY1Rl79i+n7uEojX/dNakPALl532FWZ/SnO5KMe901gRqYcEXzvm1UZyTdMJLSHXGTUHdt7v3bUlY3Pz/vS0tLtZ8XQP3SUgptL4Wa1HPuTE9lBumZzrTMpJXDazoj5fGoVIaY2T53n096jh41MOHaqujIS6+kDRROmeloQodypjOtI88dO/6eldW148/FH49DZQiDicCEa6OiI217sE0Ld2vbrkXt2b+cemM46p44kGmmzN523KhXhhCogQnXRkVH1vZgvR7vzOnTie/t7cHYvyfjyuG1xNenGeXKEFIfwIRro6IjL0iurh3VqSefdEJOunfDSBrIvPmeg7k72cSNcmUIgRpA4xUdRbYH+97qmm65ZkvhG0aRnWx6Rr0yhEANoHFFtwdL2vDg+t0HCtV2F636GMW1QgjUABoXD6rLK6syPZ+jlk7s8dZd2x2f2Rj/7FGpCGEwEUArdmyd096F7fr6rtfolmu2nDA4WKRUb5DKjXjFibT+BlHlvG2iRw2gVkVSC3k94Tpru/NmNg563jYRqAHUpq5lSOvcS7FIEN4406mUu246703qA0Bt6kpZ1FnbnRfcO9NTuuzC2RMm5Nx4x8Pas3859/xJk3mKvrcoAjWA2tSVstixdS5xkssgvdSkoG/R19557/vyoYFvMG2skU3qA0Bt6kxZ1FXbXWRCz/W7DyS+N+sG00t3tLFGNoEaQG2S6qVDmGySF/TL3mDaXiOb1AeA2tSZsmhT2Zx422tk06MGUKs2NhioW9n1TrLSGnMNVH0QqAFA5W4waamSpjZbIPUBACW1vdkvPWoAKKntzX5zA7WZfVjSayU97e4va6QVADAEVWYUtpmLL5L6+IikKxtuBwC0qo0ZhXXJDdTu/oCkZ1poCwC0po0ZhXWpbTDRzHaa2ZKZLR06dKiu0wJAI9rafb0OtQVqd7/V3efdfX52drau0wJAI9rYfb0ulOcBmEhtl9hVQXkegImUVWIX2r6KRcrzbpP0KklnmdmTkt7t7h9qumEA0LSkEru6Nj+oU26gdvc3tNEQAAhBVjXIsAI1OWoAiAmxGoRADQAxIVaDEKgBICarGmTP/mVt27WozQt3a9uuxdZmMVL1AQAxadUgkoY2yEigBoA+8WqQrL0R2xpkJFADQIoieyO2MchIjhoAUuTtjSi1M8hIoAaAFHm95bamnBOoASBFVm+5zR3WCdQAkCKtVO9912zR3oXtrc1UZDARAFK0vTdiGgI1AGRoc2/ENKQ+ACBwBGoACByBGgACR6AGgMARqAEgcObu9Z/U7JCkbwz49rMkfafG5tSFdpVDu8qhXeWMY7vOc/fZpCcaCdRVmNmSu88Pux39aFc5tKsc2lXOpLWL1AcABI5ADQCBCzFQ3zrsBqSgXeXQrnJoVzkT1a7gctQAgPVC7FEDAGII1AAQuKEEajP7FTN7xMyOmVlqKYuZXWlmB83scTNbiB3fbGYPRcd3m9kpNbXrTDO718wei75uSHjNZWZ2IPbvf81sR/TcR8zsa7HntrTVruh1R2OffVfs+DCv1xYz+1z08/6CmV0Te67W65X2+xJ7/tTov//x6Hpsij13Y3T8oJldUaUdA7TrHWb2pej6fNbMzos9l/gzbaldbzKzQ7HP/63Yc9dFP/fHzOy6ltt1S6xNXzGzldhzjVwvM/uwmT1tZl9Med7M7C+iNn/BzF4Re676tXL31v9J+glJF0i6X9J8ymumJH1V0vmSTpH0eUkXRc99QtK10eMPSHprTe36M0kL0eMFSX+a8/ozJT0j6fTo+49Ien0D16tQuyT9IOX40K6XpB+X9NLo8UZJT0maqft6Zf2+xF7zO5I+ED2+VtLu6PFF0etPlbQ5Os9Ui+26LPY79NZeu7J+pi21602S/jLhvWdKeiL6uiF6vKGtdvW9/nclfbiF6/Wzkl4h6Yspz79a0qclmaRLJT1U57UaSo/a3R9194M5L7tE0uPu/oS7/5+kj0u62sxM0nZJt0ev+6ikHTU17erofEXP+3pJn3b3wzV9fpqy7Tpu2NfL3b/i7o9Fj78l6WlJibOvKkr8fclo7+2Sfi66PldL+ri7H3H3r0l6PDpfK+1y9/tiv0MPSjqnps+u1K4MV0i6192fcfdnJd0r6cohtesNkm6r6bNTufsD6nbK0lwt6W+860FJM2Z2tmq6ViHnqOckfTP2/ZPRsRdJWnH35/qO1+HF7v5U9Pi/JL045/XX6sRfkvdGf/rcYmanttyu08xsycwe7KVjFND1MrNL1O0lfTV2uK7rlfb7kvia6Hp8T93rU+S9TbYr7s3q9sx6kn6mbbbrl6Ofz+1m9pKS722yXYpSRJslLcYON3W98qS1u5Zr1dgOL2b2GUk/mvDUu9z9H5v63DxZ7Yp/4+5uZqm1i9Hd8mJJ98QO36huwDpF3XrKP5T0Jy226zx3Xzaz8yUtmtnD6gajgdV8vf5W0nXufiw6PPD1Gkdm9kZJ85JeGTt8ws/U3b+afIba/ZOk29z9iJn9trp/jWxv6bOLuFbS7e5+NHZsmNerMY0Fanf/+YqnWJb0ktj350THvqvunxUnR72i3vHK7TKzb5vZ2e7+VBRYns441a9KutPd12Ln7vUuj5jZX0t6Z5vtcvfl6OsTZna/pK2SPqkhXy8ze6Gku9W9ST8YO/fA1ytB2u9L0mueNLOTJZ2h7u9Tkfc22S6Z2c+re/N7pbsf6R1P+ZnWEXhy2+Xu3419+0F1xyR6731V33vvr6FNhdoVc62kt8UPNHi98qS1u5ZrFXLq4z8kvdS6FQunqPtDucu7Gfr71M0PS9J1kurqod8Vna/IeU/IjUXBqpcX3iEpcYS4iXaZ2YZe6sDMzpK0TdKXhn29op/dnerm727ve67O65X4+5LR3tdLWoyuz12SrrVuVchmSS+V9O8V2lKqXWa2VdJfSbrK3Z+OHU/8mbbYrrNj314l6dHo8T2SLo/at0HS5Vr/l2Wj7YradqG6g3Ofix1r8nrluUvSr0fVH5dK+l7UEannWjUxQpr3T9IvqZurOSLp25LuiY5vlPSp2OteLekr6t4R3xU7fr66/yM9LukfJJ1aU7teJOmzkh6T9BlJZ0bH5yV9MPa6TereKU/qe/+ipIfVDTgfk/SCttol6aejz/589PXNIVwvSW+UtCbpQOzfliauV9Lvi7qplKuix6dF//2PR9fj/Nh73xW976CkX6z59z2vXZ+J/j/oXZ+78n6mLbXrJkmPRJ9/n6QLY+/9zeg6Pi7pN9psV/T9eyTt6ntfY9dL3U7ZU9Hv8pPqjiW8RdJboudN0vujNj+sWDVbHdeKKeQAELiQUx8AABGoASB4BGoACByBGgACR6AGgMARqAEgcARqAAjc/wMXJ7uiSdnTTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### generate equally spaced x-values\n",
    "x = np.linspace(-1, 1, n) \n",
    "### generate y-values (we use a numpy library so we can generate a vector of numbers - y - inline)\n",
    "y = a * x + b + np.random.normal(scale=0.25, size=n)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3) As you may see, the samples are placed - more or less - along a single line.\n",
    "Now, our aim is to find the best parameters for a linear function \n",
    "so that such defined model describes the given data in the best possible way. For this reason, we will iteratively search the parameter space and thus update the model. Firstly, we need to define an error function. This function will inform how well (or bad) the instantiated model describes the data. For this reason, we use a mean square error function. <br>\n",
    "\n",
    "We define a mean square error function as:<br>\n",
    "$\\dfrac{\\sum\\left(y_i - \\widehat{y}_i \\right)^2}{n} = MSE,$\n",
    "\n",
    "where $y$ are the target (i.e., data values) and $\\widehat{y}$ are the output (i.e., model's) values. <br>\n",
    "\n",
    "See the MSE (mean square error) function given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_target, y_calc):\n",
    "    return ((y_target - y_calc) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Run the below code for different parameters of the model. Which parameter values give the best (i.e., minimal) MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.06139158207512604, for a = -2.0 and b = 3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_list = [-3.0 + i*0.25 for i in range(13)]\n",
    "b_list = [-4.0 + i*0.5 for i in range(19)]\n",
    "best_score = np.inf\n",
    "best_ycalc = None\n",
    "best_a = None\n",
    "best_b = None\n",
    "for a_2 in a_list:\n",
    "    for b_2 in b_list:\n",
    "        # print(f'{a_2}x + {b_2}')\n",
    "        ycalc = a_2*x + b_2\n",
    "        score = mse(y, ycalc)\n",
    "        if score < best_score:\n",
    "            # print(\"\\tbetter\")\n",
    "            best_a = a_2\n",
    "            best_b = b_2\n",
    "            best_score = score \n",
    "            best_ycalc = ycalc\n",
    "print(f'MSE = {best_score}, for a = {best_a} and b = {best_b}')\n",
    "\n",
    "plt.scatter(x, y, label=\"target\")\n",
    "plt.scatter(x, best_ycalc, label=\"calculated\")\n",
    "plt.legend()\n",
    "\n",
    "y_calc = best_ycalc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) We want to find the best possible model parameters automatically. For this reason, we use a gradient of a loss function. The gradient informs what is the direction of the fastest increase/decrease of a given function. We use this information to update both model parameters. This procedure will be performed iterativelly. In each iteration, the parameters a and b will be slightly modififed such that MSE will be reduced (i.e., improved). <br>\n",
    "\n",
    "Firstly, finish the below function. It should calculate a batch gradient of a loss function, i.e., **MSE for each point separately** (y_target, and y_calc are array,  not just scalars, so output also should be array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.003728776549995842, 0.23465602812604727, 0.03404139399468124, 0.0182640850691505, 0.01806910300997247, 0.035312983132517316, 0.025548272059138465, 0.011867207442872948, 0.09164247811770843, 0.041196701189461574, 0.30615789135755306, 0.04303439009552524, 0.02034226245832011, 0.041051480260456, 0.15637455066634157, 0.012337606932380042, 0.037479554378879607, 0.003830362194941659, 0.014083076223779111, 0.00045369674126731404, 0.002171113540046711, 0.26121335842455506, 0.03500544576526754, 0.004612130562081373, 0.20836607996831613, 0.03295658419299487, 0.21187198097689794, 0.12239182976406124, 0.020590917842726795, 0.0029823295381938815, 0.009564912682593357, 0.2316273830422819, 0.09233840703589198, 0.006405422267247652, 0.0017311594754103276, 0.02605177971185287, 0.03676132262170064, 0.00026618827637814194, 0.06097997763315236, 1.6684773949518333e-05, 0.022838049074104708, 0.13407644488377848, 0.06871053075356147, 0.07861262534400455, 0.0050515684855469145, 0.010440105916138575, 0.03395895643651038, 0.2285749101489601, 0.001447542775613502, 0.01170676330777243, 0.0001426507117898918, 0.1358212132690592, 0.0028164200358018593, 0.0033512532562426306, 0.0112738300557031, 0.2461891967032283, 0.020448966638597233, 0.012263936883191651, 0.052429550954637055, 0.0022439109139916007, 4.113688385588196e-05, 0.011273289919357287, 0.0006535571659841297, 0.04711050461913247, 0.058744998527845996, 0.12431997280649007, 0.000273626174466462, 0.0031491445270970374, 0.25919048159235786, 0.09030552213486692, 0.07014314262291318, 0.010414182089083929, 0.12496013246175953, 0.25552795924618155, 0.03749532565227536, 0.013597986300587095, 0.06022587363137008, 0.07214914596681361, 0.03432905707734974, 0.2923187967489978, 0.18694488994572445, 0.06836522044203971, 0.06370569312039766, 0.03003778310063775, 0.009069922503036227, 0.04829966696283195, 0.0009896034030856462, 0.022790016982565664, 0.002584887927264224, 0.008843120604412537, 0.014778381443953754, 1.1867236851788214e-07, 0.004102973919111067, 0.05313311866325685, 0.0021334097710095147, 0.08451454714319293, 0.17591021803438753, 0.10695790557798017, 0.021866348612653994, 0.06813120988908375]\n"
     ]
    }
   ],
   "source": [
    "def mse_grad(y_target, y_calc):\n",
    "    n = len(y_target)\n",
    "    errors = [0.0 for i in range(n)]\n",
    "    for i in range(n):\n",
    "        errors[i] = mse(y_target[i], y_calc[i])\n",
    "    return errors\n",
    "\n",
    "\n",
    "### TEST\n",
    "print(mse_grad(y, y_calc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6) Fill the update function to calculate gradient of parameter $a$ and $b$ basing on a gradient of loss function (grad_y) and input vector (x).\n",
    "Then update the parameter $a$ and $b$ base on their gradients and learning rate (lr). To update parameters use batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.a * x + self.b\n",
    "\n",
    "    def update(self, x, grad_y, lr):\n",
    "        def getShifts() -> (float, float):\n",
    "            def getShift_a() -> float:\n",
    "                #todo\n",
    "            \n",
    "            def getShift_b() -> float:\n",
    "                #todo\n",
    "            \n",
    "            return getShift_a(), getShift_b()\n",
    "            \n",
    "        \n",
    "        # calculate shifts\n",
    "        shift_a, shift_b = getShifts()\n",
    "        \n",
    "        # update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7) Write Step function which calculates: y_calc output of the model base on input x, loss of the model, gradient of loss, and update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Step(x, y, model, lr):\n",
    "    #TODO\n",
    "\n",
    "    return y_calc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8) Fit the model for 100 epochs, with learning rate 0.05, and with initial value of parameters a = 1.1, and b = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearLayer(1.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "losses = []\n",
    "for i in range(epoch):\n",
    "    y_calc, loss = Step(x, y, model, lr)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animation of the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearLayer(1.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(x, y)\n",
    "line, = plt.plot(x, y_calc, \".\", c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    y_calc, loss = Step(x, y, model, lr)\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, epoch), interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.9) There is an example it can be done in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to torch tensor, [:,None] add an additional dimension\n",
    "xt = torch.FloatTensor(x[:, None])\n",
    "yt = torch.FloatTensor(y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_target, y_calc):\n",
    "    return ((y_target - y_calc) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        super(LinearLayer, self).__init__()  # initialize torch functionality\n",
    "        # change a and b to float tensor, and next to parameters,\n",
    "        # the main difference between tensor and parameter is that parameter keeps information about calculations,\n",
    "        # which is used to calculate gradients\n",
    "        self.a = nn.Parameter(torch.FloatTensor([a]).view(1, 1))\n",
    "        self.b = nn.Parameter(torch.FloatTensor([b]))\n",
    "\n",
    "    # forward function is similar to python __call__ but also contain torch functionality\n",
    "    def forward(self, x):\n",
    "        return  x @ self.a + self.b  # linear equation, @ means matrix multiplication for tensor\n",
    "\n",
    "    def update(self, lr):\n",
    "        with torch.no_grad():  # when we update parameter, we have to switch off gradient tracking\n",
    "            self.a.sub_(lr * self.a.grad)  # inplace update of parameter a\n",
    "            self.a.grad.zero_()  # clear gradient\n",
    "\n",
    "            self.b.sub_(lr * self.b.grad)\n",
    "            self.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  LinearLayer(-1.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchStep(x, y, model, lr):\n",
    "    y_calc = model(x)  # calculate the output of our model\n",
    "    loss = mse(y, y_calc)  # calculate the loss\n",
    "    loss.backward()  # calculate all gradients\n",
    "    model.update(lr)  # update parameters\n",
    "    return loss, y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, y_calc = torchStep(xt, yt, model, lr)\n",
    "y_calc = y_calc.detach().cpu()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xt[:, 0], yt)\n",
    "line, = plt.plot(xt[:, 0], y_calc, c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    loss, y_calc = torchStep(xt, yt, model, lr)\n",
    "    y_calc = y_calc.detach().cpu()  #\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, 100), interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use optymalizer to update parameters base on their gradients\n",
    "# the most simple is stochastic gradient descent (SGD)\n",
    "def torchStep2(x, y, model, optim):\n",
    "    optim.zero_grad()  # clear gradients\n",
    "    y_calc = model(x)  # calculate output of model\n",
    "    loss = mse(y, y_calc)  # calculate loss\n",
    "    loss.backward()  # calculate all gradients\n",
    "    optim.step()  # make a optymalizer step which update parameters\n",
    "    return loss, y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearLayer(-1.1, 0.2)\n",
    "optim = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, y_calc = torchStep2(xt, yt, model, optim)\n",
    "y_calc = y_calc.detach().cpu()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xt[:, 0], yt)\n",
    "line, = plt.plot(xt[:, 0], y_calc, c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    loss, y_calc = torchStep2(xt, yt, model, optim)\n",
    "    y_calc = y_calc.detach().cpu()\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, 100), interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "image = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Write a function which calculates a convolution on an input matrix (image) using kernel (mask) with shape 3x3 and bias. Do not use padding, so the output image should be in size: (input_wight -2) x (input_height -2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution(image, kernel, bias):\n",
    "    img_out = np.zeros((image.shape[0] - 2, image.shape[1] - 2))\n",
    "    #TODO\n",
    "            \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel (mask) which is mean filter\n",
    "kernel = np.ones((3, 3)) / 9\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = Convolution(image, kernel, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Find out kernels (masks) which found horizontal and vertical lines. Pixels belonging to the line should be greater than zero and the others less than zero. Use size 3x3 masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example <br>\n",
    "print(Convolution(np.array([[0,0,0,0,0],[0,0,0,0,0],[1,1,1,1,1],[0,0,0,0,0],[0,0,0,0,0]]), kernel_horizontal, -2)) <br>\n",
    "[[-1. -1. -1.]<br>\n",
    " [ 1.  1.  1.]<br>\n",
    " [-1. -1. -1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_horizontal ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_horizontal = Convolution(image, kernel_horizontal, -2)\n",
    "plt.imshow(img_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_vertical = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vertical = Convolution(image, kernel_vertical, -2)\n",
    "plt.imshow(img_vertical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Complete function to calculate ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Find bias values such that output images pixels have a value above 0 only if original pixel is a part of the horizontal/vertical line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(relu(img_horizontal))\n",
    "plt.show()\n",
    "plt.imshow(relu(img_vertical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "df = pd.read_csv('data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n - number of elements in dataset\n",
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variables\n",
    "feature_columns = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]\n",
    "target_column = \"variety\"\n",
    "class_number = 3\n",
    "feature_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries use to map class name to number\n",
    "name_to_class = {0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"}\n",
    "class_to_name = {\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of class name\n",
    "df[target_column] = df[target_column].apply(lambda x: class_to_name[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take raw numpy data\n",
    "x = df[feature_columns].values\n",
    "y = df[target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data to make network input mean value equals 0 and standard deviation 1\n",
    "x = (x - x.mean(0)) / x.std(0)\n",
    "print(x.mean(0))\n",
    "print(x.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion numpy array to torch tensor\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple neural network with one hidden layer with hidden_nr neuron\n",
    "# input_layer calculate some features  which are used by hidden_layer to calculate prediction\n",
    "# between input_layer and hidden_layer there is relu  as a nonlinear activation function\n",
    "# after hidden_layer there is sigmoid function because we want the network to return the result as a probability of each class in range [0,1]\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_nr, hidden_nr, output_nr):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_nr, hidden_nr)\n",
    "        self.hidden_layer = nn.Linear(hidden_nr, output_nr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss is equal $- (y=0) * log(p_0) - (y=1) * log(p_1)  - (y=2) * log(p_2)$ where $p_1, p_2,p_3$ are calculated probability of class 1,2,3; and y=0 means y is classified to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy means how many samples are classified correctly\n",
    "def Accuracy(y_target, y_calc):\n",
    "    prediction_class = y_calc.max(1)[1]\n",
    "    number_of_correct = (prediction_class == y).float().sum()\n",
    "    return number_of_correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Step(x, y, model, optim):\n",
    "    optim.zero_grad()\n",
    "    y_calc = model(x)\n",
    "    loss = loss_func(y_calc, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    acc = Accuracy(y, y_calc)\n",
    "    return loss, y_calc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function train model for epoch step, and collect metrics (loss and accuracy)\n",
    "def Train(x, y, model, optim, epoch):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i in range(epoch):\n",
    "        loss, y_calc, acc = Step(x, y, model, optim)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(acc)\n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model and optimalizer\n",
    "hidden_nr = 5\n",
    "model = Net(feature_number, hidden_nr, class_number)\n",
    "optim = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200\n",
    "losses, accuracies = Train(x, y, model, optim, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task for 5:\n",
    "Choose one of the following 3.1 or 3.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1) Create a report of testing different values of learning rate, and number of neurons in hidden layer; Run every test 10 times with 200 epochs. Make a plot of mean of losses and accuracy of each value in the test case. Make a table of score after 200 epochs of learning which should contain best, worst, mean and standard deviation of loss and accuracy (you can use pandas describe function).  \n",
    "\n",
    "    test case 1: \n",
    "    learning rate:[ 1, 0.5, 0.1, 0.01, 0.001]\n",
    "    number of neuron in hidden layer: 10\n",
    "    \n",
    "    test case 2: \n",
    "    number of neuron in hidden layer: [1, 2, 5, 10, 20, 100]\n",
    "    learning rate: 0.1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) You can try to make an image classifier shown in fastai coures https://docs.fast.ai/\n",
    "* [video](https://course.fast.ai/videos/?lesson=2)\n",
    "* [notebook](https://github.com/fastai/fastbook/blob/master/02_production.ipynb)\n",
    "\n",
    "**(old version of fastai 1.0.61 and pytorch 1.2)**\n",
    "* [video](https://course17.fast.ai/lessons/lesson2.html) You should watch all video, but after 16.30 there are creating your own dataset and next create an image classifier. \n",
    "* [notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb)\n",
    "\n",
    "\n",
    "You can use animals dataset or prepare your own dataset, but it should contain at least 4 different classes.\n",
    "\n",
    "    To finish this task you should prepare a report by creating a classifier, and show working neural network at the laboratory.\n",
    "    The report should contain:\n",
    "        - describe of dataset: number of samples, some examples, how it was prepared, number of samples in train and validation set, are there images which contains more than one class, batch size\n",
    "        - describe of model: tested models\n",
    "        - describe of training: how testing looks like, how many epoch, how long it takes, data cleaning, learning rate finder and so on, plots of losses, and accuracy\n",
    "        - describe of result: confusion matrix, examples of correct classified image, examples of incorrect classified image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}