{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import common as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: this exercise uses Pandas (for data manipulation and analysis) and Graphviz (for graph-drawing) libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise consists of 3 parts. Complete the first part to get a mark of 3.0, the first two parts to get 4.0, complete all assignments to get 5.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 ) There are 10 objects (data) characterized with 5 binary attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeNames = [\"attr 1\", \"attr 2\", \"attr 3\", \"attr 4\", \"attr 5\"]\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    [\n",
    "        [1, 0, 1, 1, 1],\n",
    "        [1, 1, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 1],\n",
    "        [1, 0, 1, 0, 1],\n",
    "        [1, 0, 0, 1, 1],\n",
    "        [0, 0, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [1, 0, 0, 1, 1],\n",
    "        [0, 1, 0, 0, 1],\n",
    "        [0, 0, 0, 1, 1],\n",
    "    ],\n",
    "    columns=attributeNames,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Each object is assigned to either a class \"0\" or \"1\". The assignments are as follows (cl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cl\"] = [1, 1, 1, 0, 0, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: How one can read data (columns) in Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"cl\"])\n",
    "print(list(data[\"cl\"]))\n",
    "print(set(data[\"cl\"]))\n",
    "print(data[\"attr 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: How split data (Pandas DataFrame) base on column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['cl']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: How take values from column (Pandas Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, row in data['cl'].items():\n",
    "    print(id,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 )  Finish the below function for calculating entropy. $H(CL) = - \\sum_{y \\in CL}p(y)log_2p(y)$ It should return a value of entropy for an input vector CL. Assume that $log_2(0)$ is equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(cl):\n",
    "    ### TODO\n",
    "    ### return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 ) Calculate the entropy for the CL vector  (the result should be 0.97095...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) Finish the below function for calculating a conditional entropy: $H(CL|X) = - \\sum_{x \\in X} \\sum_{y \\in CL} p(x,y) log_2 \\frac{p(x,y)}{p(x)}$. Assume that $log_2(0)$ is equal to 0 and if $p(x) = 0$, $\\frac{p(x,y)}{p(x)}$ is equal to 0 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConditionalEntropy(cl, attr):\n",
    "    ### TODO\n",
    "    ### return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 ) Calculate conditional entropies for given attribiutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getConditionalEntropy(data[\"cl\"], data[\"attr 1\"])) ### the result should be 0.95097...\n",
    "print(getConditionalEntropy(data[\"cl\"], data[\"attr 5\"])) ### the result should be 0.97095..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7 ) **Question: Which entropy is lesser and why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8) Finish the below function for calculating information gain (use getEntropy() and getConditionalEntropy() functions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInformationGain(cl, attr):\n",
    "    ### TODO\n",
    "    ### return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getInformationGain(data[\"cl\"], data[\"attr 1\"]))\n",
    "print(getInformationGain(data[\"cl\"], data[\"attr 5\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.9) **Question: Which IG is lesser and why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: ID3 algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree consists of decision nodes and leaves. Nodes split data while leaves classify objects. Consider the class \"Node\" provided below. It consists of 4 fields:\n",
    "- attr - attribute ID (use the names in attributeNames vector)\n",
    "- left - left branch, i.e., a reference to other node\n",
    "- right - right branch, i.e., a reference to other node\n",
    "- value - a decision. If node = None, then the node is not a leaf. If value is not None, then a node is considered a leaf. \n",
    "\n",
    "Method __call__ returns the decision if the node is a leaf (i.e., when value is not None). \n",
    "Otherwise, it calls either the left or the right branch of an input object, based on the attribute value (0 -> left children; 1 -> right children). In this way, we can traverse the decision tree in order to find the final decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attr, left, right, value):\n",
    "        self.attr = attr\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def __call__(self, obj):\n",
    "        if self.value is None:\n",
    "            if obj[self.attr] == 0:\n",
    "                return self.left(obj)\n",
    "            else:\n",
    "                return self.right(obj)\n",
    "        else:\n",
    "            return self.value\n",
    "        \n",
    "### EXAMPLE\n",
    "def example(obj):\n",
    "    root = Node(0, None, None, None) ###  IN ROOT SPLIT ON 1ST (0) ATTRIBUTE\n",
    "    lChildren = Node(1, None, None, None) ### IN ROOT's LEFT CHILDREN SPLIT ON 2ND (1) ATTRIBUTE\n",
    "    rChildren = Node(None, None, None, 2) ### IN ROOT's RIGHT CHILDREN -> DECISION = 2\n",
    "    root.left = lChildren\n",
    "    root.right = rChildren\n",
    "    llChildren = Node(None, None, None, 3) ### IN ROOT's LEFT-LEFT CHILDREN -> DECISION = 3\n",
    "    lrChildren = Node(None, None, None, 4) ### IN ROOT's LEFT-RIGHT CHILDREN -> DECISION = 4\n",
    "    lChildren.left = llChildren\n",
    "    lChildren.right = lrChildren\n",
    "    print(root(obj))\n",
    "    \n",
    "example([0, 0]) ### ROOT : FIRST ATTRIBUTE = 0 SO WE GO TO LEFT CHILDREN.\n",
    "### IT IS A LEAF WITH THE DECISION = 3\n",
    "### THEN, IN THE CORRESPONDING CHILDREN, THE SECOND ATTRIBUTE = 0, SO WE GO TO LEFT-LEFT CHILDREN\n",
    "\n",
    "example([0, 1]) \n",
    "example([1, 0])\n",
    "example([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Create an initial root. Set the value (decision) to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Use a getErrorRate method in common.py auxiliary file to calculate the error rate. The decision is made based on the majority rule. In case of tie, the method takes 0 as the default class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "## SHOULD BE 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Use printGraph method (see the common.py file) to draw the decision tree and save it in a png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Calculate information gain for all attribiutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInformationGain(data):\n",
    "    for attribute_name in attributeNames:\n",
    "        ### TODO\n",
    "        ### print()\n",
    "        \n",
    "printInformationGain(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5) Choose the best attribute to split the data (HINT, it should be the third attribute :)). Construct two new nodes: one for $x_i$ = 0 decision and the second for $x_i$ = 1; connect them with the root (left and right branch). Remember to update the root. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6) Print the graph and calculate the error rate. What happened with the error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7) Split the 'data' (table) based on the selected attribiute, i.e., create two new tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "### left_data = \n",
    "### right_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8) Let us start with the left node. Firstly, calculate information gain for this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9) Choose the best attribute to split the data and then update the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.10) Print the graph and calculate the error rate (HINT: should be 0.2 :). What happened with the error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.11) Split data (remember that we split left_data, not data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "### leftLeft_data = \n",
    "### leftRight_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.12) Repeat the whole process for the right node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute the information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO print the decision tree and calculate the error rate (HINT, should be 0.1:) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO split the data (right_data)\n",
    "#rightLeft_data\n",
    "#rightRight_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.13) Let's consider left-left node. Calculate information gain for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.14) Will adding a new node to the tree improve its effectiveness? Why? Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.15) Calculate information gain for the left-right node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printInformationGain(leftRight_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the attribute and update the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print the decision tree and compute the error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.16) What happened with the error rate? Is it necessary to keep these two newly added leaves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.17) Finish creating the right side of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: automated construction of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Complete the following function for automated construct of decision trees, so that it returns a decision tree for the given data and attribute list. Note that this is a recusive method, i.e., calls itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 0\n",
    "\n",
    "def createTree(data, attributeNames, depth=0):\n",
    "    data = data.reset_index().drop(\"index\", axis=1)\n",
    "    ### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) Build a decision tree for a training dataset in the common.py auxiliary file, for diffrent values of max_depth.  Calculate & compare the error rates for training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_attributeNames, train_data = cm.getTrainingDataSet()\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "valid_attributesName, valid_data = cm.getValidationDataSet()\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3) Consider only the training data set and answer the following questions:\n",
    "* What is the miximum depth of the tree (consider only the training data set)?\n",
    "* The tree building process should stop when there is no improvement in error rate (why?). Check for which value of \"max_dept\" there is no improvement in error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    max_depth = i\n",
    "    ### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
